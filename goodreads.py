import streamlit as st
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import os
import time
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer


st.set_page_config(page_title='Estad√≠sticas de Goodreads', layout='wide')

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}
base_url = 'https://www.goodreads.com'

countries = {
    'Todo el mundo': 'all',
    'Estados Unidos': 'US',
    'Espa√±a': 'ES',
    'Alemania': 'DE',
    'Reino Unido': 'GB',
    'Italia': 'IT',
    'Canad√°': 'CA',
    'M√©xico': 'MX',
    'Argentina': 'AR',
    'Australia':'AU'
}

def scrape_book_details(book_url):
    book_page_url = base_url + book_url
    response = requests.get(book_page_url, headers=headers)
    time.sleep(1)
    if response.status_code != 200:
        st.error(f"Error al obtener datos: {response.status_code}")
        return

    soup = BeautifulSoup(response.text, 'html.parser')
    genres = [genre.text.strip() for genre in soup.find_all('span', {'class': 'BookPageMetadataSection__genreButton'})]
    pages_info = soup.find('div', {'class': 'FeaturedDetails'})
    pages = None
    publication_date = None
    if pages_info:
        pages_text = pages_info.find('p', {'data-testid': 'pagesFormat'})
        if pages_text:
            pages = int(pages_text.text.strip().split()[0])
        pub_date_text = pages_info.find('p', {'data-testid': 'publicationInfo'})
        if pub_date_text:
            try:
                publication_date = datetime.strptime(pub_date_text.text.replace('First published', '').replace('Published', '').strip(), '%B %d, %Y').strftime('%d-%m-%Y')
            except ValueError:
                publication_date = None
    synopsis = soup.find('span', {'class': 'Formatted'})
    synopsis_text = synopsis.get_text(strip=True) if synopsis else ''
    reviews = []
    reviews_list = soup.find_all('article', {'class': 'ReviewCard'})
    for review in reviews_list:
        rating = review.find('span', {'class': 'RatingStars RatingStars__small'})
        review_rating = None
        if rating:
            review_rating = int(rating['aria-label'].split()[1])
        review_content = review.find('span', {'class': 'Formatted'})
        review_text = review_content.get_text(strip=True) if review_content else ''
        reviews.append({'rating': review_rating, 'content': review_text})
    return {
        'genres': genres,
        'pages': pages,
        'publication_date': publication_date,
        'synopsis': synopsis_text,
        'reviews': reviews
    }

def scrape_and_save(country='all', duration='y', filename=None):
    try:
        if filename is None:
            filename = f'{country}_most_read_books_{duration}.csv'
            
        url = f'https://www.goodreads.com/book/most_read?category=all&country={country}&duration={duration}'
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return
        soup = BeautifulSoup(response.text, 'html.parser')
        books_container = soup.find('table', {'class': 'tableList'})
        if not books_container:
            st.error('No se encontraron datos en Goodreads para los par√°metros especificados.')
            return None
        
        data = []
        for book in books_container.find_all('tr', {'itemtype': 'http://schema.org/Book'}):
            try:
                ranking = int(book.find('td', {'class': 'number'}).text)
                title = book.find('a', {'class': 'bookTitle'}).get_text()
                author = book.find('a', {'class': 'authorName'}).get_text()
                avg_rating = float(book.find('span', {'class': 'minirating'}).get_text(strip=True).split(' ')[0])
                total_rating = int(book.find('span', {'class': 'minirating'}).get_text(strip=True).split(' ')[4].replace(',', ''))
                readers = int(book.find('span', {'class': 'greyText statistic'}).get_text(strip=True).split()[0].replace(',', ''))
                href = book.find('a', {'class': 'bookTitle'})['href']
                book_details = scrape_book_details(href)
                data.append({
                    'Ranking': ranking,
                    'T√≠tulo': title,
                    'Autor': author,
                    'Calificaci√≥n promedio': avg_rating,
                    'Total de calificaciones': total_rating,
                    'N√∫mero de lectores': readers,
                    'Genres': ', '.join(book_details.get('genres', [])),
                    'P√°ginas': book_details.get('pages', ''),
                    'Fecha de publicaci√≥n': book_details.get('publication_date', ''),
                    'Synopsis': book_details.get('synopsis', ''),
                    'Reviews': book_details.get('reviews', [])
                })
                
            except AttributeError:
                continue
        if data:
            df = pd.DataFrame(data)
            df.to_csv(filename, index=False)
            return filename
            
    except Exception as e:
        st.error(f"Error inesperado: {e}")
        

def load_data(filename):
    return pd.read_csv(filename)

def show_main_insights(df):
    st.header('Top 50 Libros Le√≠dos')
    if df is not None:
        df_resumen = df.drop(columns=['Reviews','Synopsis','Genres'])
        st.dataframe(df_resumen, hide_index=True)
        # Subheader para g√©neros m√°s populares
        st.subheader('An√°lisis de Libros')
        all_genres = ', '.join(df['Genres'].dropna()[df['Genres'].apply(lambda x: isinstance(x, str))])
        genre_counts = Counter(all_genres.split(', '))
        genres_df = pd.DataFrame(genre_counts.items(), columns=['G√©nero', 'Popularidad']).sort_values(by='Popularidad', ascending=False)
        top_genres = genres_df.head(10)  # Seleccionar los 10 g√©neros m√°s populares
       
       # Gr√°fico de barras con Plotly
        fig_genres = px.bar(top_genres, 
                            x='G√©nero', 
                            y='Popularidad', 
                            text='Popularidad', 
                            title='Top 10 G√©neros M√°s Populares',  
                            color='Popularidad', 
                            color_continuous_scale='Viridis')
        
        fig_genres.update_traces(textposition='outside')
        fig_genres.update_layout(xaxis_title='G√©nero', yaxis_title='Popularidad', showlegend=False)
        st.plotly_chart(fig_genres)
        
        # Trace de la visualizaci√≥n
        trace = go.Scatterpolar(
            r=top_genres['Popularidad'],  # Popularidad como el valor radial
            theta=top_genres['G√©nero'],   # G√©neros como las categor√≠as del eje angular
            fill='toself',  # Llenar el √°rea del gr√°fico
            name='Top G√©neros',  # Nombre para la leyenda
            marker=dict(color='cyan'),  # Color de los puntos
        )
        
        # Layout del gr√°fico
        layout = go.Layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,  # Hacer visible el eje radial
                    range=[0, top_genres['Popularidad'].max() * 1.1],  # Ajustar el rango radial
                ),
                angularaxis=dict(
                    tickmode='array',  # Asegurarse de que se muestren todos los g√©neros
                    tickvals=top_genres['G√©nero'],  # Etiquetas de los g√©neros
                ),
            ),
            showlegend=False,  # Ocultar la leyenda si no es necesaria
            template='plotly_dark',  # Estilo oscuro
        )
        
        # Crear la figura y mostrar el gr√°fico
        fig = go.Figure(data=[trace], layout=layout)
        
        # Mostrar el gr√°fico en Streamlit
        st.plotly_chart(fig)
        
        if 'Fecha de publicaci√≥n' in df.columns:
        # Asegurarse de que las fechas est√°n en formato correcto y extraer el a√±o
            df['A√±o de publicaci√≥n'] = pd.to_datetime(df['Fecha de publicaci√≥n'], errors='coerce').dt.year
            
            # Limpiar y separar g√©neros en listas
            df['Genres'] = df['Genres'].apply(lambda x: [genre.strip() for genre in str(x).split(',')])  # Separar g√©neros y quitar espacios extra
            
            # Tomar solo los tres G√©neros de cada libro
            df['G√©nero'] = df['Genres'].apply(lambda x: x[:2] if isinstance(x, list) else [])
            
            # Explode para separar los g√©neros en filas distintas
            df_exploded = df.explode('G√©nero')
            
            # Preparar datos para el gr√°fico
            if 'A√±o de publicaci√≥n' in df_exploded.columns and 'G√©nero' in df_exploded.columns:
                # Contar la cantidad de libros por a√±o y primer g√©nero
                genre_count_by_year = df_exploded.groupby(['A√±o de publicaci√≥n', 'G√©nero']).size().reset_index(name='Cantidad')
                
                # Crear el gr√°fico de barras apiladas
                fig_genre_count_by_year = px.bar(
                    genre_count_by_year,
                    x='A√±o de publicaci√≥n',
                    y='Cantidad',
                    color='G√©nero',
                    title='Por A√±o de Publicaci√≥n',
                    labels={'A√±o de publicaci√≥n': 'A√±o', 'Cantidad': 'N√∫mero de Libros'},
                    barmode='stack',
                    template='plotly_white'
                )
                
                all_years = sorted(df['A√±o de publicaci√≥n'].dropna().unique())
                fig_genre_count_by_year.update_layout(
                    xaxis=dict(
                        tickmode='array',
                        tickvals=all_years,  # Asegura que se muestren todos los a√±os
                        ticktext=[int(year) for year in all_years]  # Etiquetas de los a√±os
                    )
            )
                # Mostrar el gr√°fico
                st.plotly_chart(fig_genre_count_by_year)


            if 'Fecha de publicaci√≥n' in df.columns:
                # Asegurarse de que las fechas est√°n en formato correcto y extraer el a√±o
                df['A√±o de publicaci√≥n'] = pd.to_datetime(df['Fecha de publicaci√≥n'], errors='coerce').dt.year
                
                # Contar la cantidad de libros por a√±o
                books_by_year = df['A√±o de publicaci√≥n'].value_counts().reset_index()
                books_by_year.columns = ['A√±o de publicaci√≥n', 'Cantidad de Libros']
                books_by_year = books_by_year.sort_values(by='A√±o de publicaci√≥n', ascending=True)
                books_by_year = books_by_year[books_by_year['Cantidad de Libros'] > 0]

                # Crear el gr√°fico de barras para la cantidad de libros por a√±o
                fig_books_by_year = px.bar(
                    books_by_year,
                    x='A√±o de publicaci√≥n',
                    y='Cantidad de Libros',
                    title = 'Libros Publicados por A√±o',
                    labels={'A√±o de publicaci√≥n': 'A√±o', 'Cantidad de Libros': 'N√∫mero de Libros'},
                    color='Cantidad de Libros',
                    color_continuous_scale='Viridis',
                    template='plotly_white'
                )
            
                # Mostrar el gr√°fico
                st.plotly_chart(fig_books_by_year)

            if 'P√°ginas' in df.columns and 'Genres' in df.columns:
               
                # Tomar solo el primer g√©nero de cada libro y asegurarse de que est√° limpio
                df['Primer G√©nero'] = df['Genres'].apply(lambda x: x[0].replace("['", "").replace("'", "").strip() if isinstance(x, list) else None)
                
                # Filtrar para evitar nulos en 'P√°ginas' o 'Primer G√©nero'
                df_filtered = df.dropna(subset=['P√°ginas', 'Primer G√©nero'])
                
                # Crear el gr√°fico de dispersi√≥n
                fig_pages_genres = px.scatter(
                    df_filtered,
                    x='P√°ginas',
                    y='Primer G√©nero',
                    color='Primer G√©nero',
                    title='Relaci√≥n entre N√∫mero de P√°ginas y G√©neros',
                    labels={'P√°ginas': 'P√°ginas', 'Primer G√©nero': 'G√©nero'},
                    color_continuous_scale='Viridis',  # O cualquier otra escala de colores
                    template='plotly_white',
                    hover_data=['T√≠tulo']  # Mostrar el t√≠tulo del libro al pasar el mouse
                )
                
                # Mostrar el gr√°fico
                st.plotly_chart(fig_pages_genres)
                
    else: 
        st.rerun()

   
    

def analyze_book_reviews(df):
    if df is not None:

        st.header('An√°lisis de Rese√±as por Libro')
        book_title = st.selectbox('Selecciona un libro', df['T√≠tulo'].unique())
        selected_book = df[df['T√≠tulo'] == book_title].iloc[0]
        st.subheader('Detalles:')
        st.write(f"**Autor:** {selected_book['Autor']}")
        st.write(f"**Calificaci√≥n promedio:** {selected_book['Calificaci√≥n promedio']}")
        st.write(f"**Total de calificaciones:** {int(selected_book['Total de calificaciones'])}")
        st.write(f"**G√©neros:** {', '.join(selected_book['Genres']).replace('[', '').replace(']', '')}")
        st.write(f"**N√∫mero de lectores:** {selected_book['N√∫mero de lectores']}")
        reviews = eval(selected_book['Reviews'])
        review_texts = [review['content'] for review in reviews if review['content']]
        sentiments = analyze_sentiment(reviews)
        all_words = ' '.join(review_texts).lower().split()
        
        # Remove stop words
        stop_words = {
        'and', 'if', 'the', 'i', 'to', 'of', 'a', 'in', 'for', 'on', 'is', 
        'it', 'that', 'this', 'with', 'as', 'are', 'was', 'at', 'by', 
        'an', 'be', 'not', 'or', 'but', 'from', 'my', 'you', 'your', 
        'he', 'she', 'they', 'we', 'all', 'so', 'what', 'there', 'when', 
        'where', 'who', 'which', 'how', 'just', 'like', 'about', 'more', 
        'than', 'up', 'out', 'some', 'other', 'no', 'yes', 'do', 'does', 
        'did', 'will', 'would', 'could', 'should', 'y', 'de', 'la', 
        'que', 'el', 'en', 'los', 'se', 'del', 'por', 'un', 'una', 
        'con', 'no', 'es', 'para', 'su', 'al', 'como', 'm√°s', 'o', 
        'pero', 'fue', 'este', 'entre', 'tambi√©n', 'hasta', 'hay', 
        'todo', 'esta', 'ser', 'son', 'me', 'si', 'sobre', 'mi', 
        'te', 'ya', 'muy', 'donde', 'quien', 'cuando', 'qu√©', 'c√≥mo', 
        'as√≠', 'solo', 'uno', 'dos', 'tres', 'cuatro', 'cinco', 
        'seis', 'siete', 'ocho', 'nueve', 'diez', 'otro', 'mismo', 
        'tanto', 'poco', 'mucho', 'cada', 'algunos', 'ninguna', 
        'varios', 'entre', 'tras', 'hacia', 'desde', 'durante', 
        'antes', 'despu√©s', 'porque', 'aunque', 'mientras', 'seg√∫n', 
        'tal', 'cual', 'donde', 'cuando', 'por qu√©', 'para que', 
        'a pesar de', 'en vez de', 'en cuanto a', 'a trav√©s de', 
        '-', '.', ',', 'ha', 'han', 'las', 'le', 'lo', 'ni', 'tan', 
        'unos', 'una', 'un', 'libro', 'bastante', 'leer', 'book', 
        'it.', 'one', 'know', 'say', 'see', 'im', 'also', 'after', 
        'before', 'between', 'during', 'while', 'such', 'these', 
        'those', 'each', 'few', 'many', 'much', 'most', 'some', 
        'any', 'none', 'all', 'whole', 'part', 'half', 'each', 'every', 
        'either', 'neither', 'both', 'few', 'many', 'much', 'most', 
        'some', 'any', 'none', 'all', 'whole', 'part', 'half', 'each', 
        'every','can', 'have', 'it\'s', 'her', 'him', 'they', 'them', 'he', 
        'she' ,'she\'s', 'he\'s', 'read','reading', 'had', 'has','because',
        'didn\'t', 'his', 'were', 'been', 'get', 'really', 'never', 'can\'t',
        'don\'t','s', 'into'}
        
        filtered_words = [word for word in all_words if word not in stop_words]
        
        word_counts = Counter(filtered_words)
    
        # Crear un DataFrame con las palabras m√°s comunes
        most_common_words = pd.DataFrame(word_counts.most_common(20), columns=['Palabra', 'Frecuencia'])
        
        # Ordenar el DataFrame en orden descendente por 'Frecuencia'
        most_common_words = most_common_words.sort_values(by='Frecuencia', ascending=False)
        
        # Crear el gr√°fico de barras con Plotly
        fig = px.bar(most_common_words, 
                     x='Palabra', 
                     y='Frecuencia', 
                     title='Palabras M√°s Frecuentes en las Rese√±as',
                     labels={'Palabra': 'Palabra', 'Frecuencia': 'Frecuencia'},
                     color='Frecuencia', 
                     color_continuous_scale='Viridis')
        
        # Mostrar el gr√°fico en Streamlit
        st.plotly_chart(fig)
    
        # Mostrar la nube de palabras
        st.subheader('Palabras Destacadas de las Rese√±as')
        wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='autumn', contour_color='black', stopwords=stop_words).generate(' '.join(filtered_words))
        plt.figure(figsize=(30, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        st.pyplot(plt)
        
        st.subheader('Rese√±as Populares (Top 30)')

    # Seleccionar la rese√±a a mostrar
        if reviews:
        # Crear las opciones para el selectbox
            options = [f"üìñ Rese√±a #{i + 1}" for i in range(len(reviews))]
        
            # Mostrar el selectbox con las opciones visuales
            review_selection = st.selectbox(
                'Selecciona una rese√±a',
                options
            )
        
            # Ajustar la selecci√≥n, ya que selectbox usa √≠ndices base 0
            review_index = options.index(review_selection)  # Obtener el √≠ndice de la rese√±a seleccionada
            selected_review = reviews[review_index]
            sentiment = sentiments[review_index]
        
            # Mostrar la rese√±a seleccionada
            if selected_review['rating']:
                st.write(f"**Rating:** {'‚òÖ' * selected_review['rating']}")
            else:
                st.write('**Sin calificaci√≥n: Pendiente de lectura**')
                
            st.write(f"**An√°lisis de opini√≥n de acuerdo al texto (puede no ser preciso):** {sentiment}")
            with st.expander("**Ver rese√±a**"):
                st.write(selected_review['content'])
        else:
            st.write("No hay rese√±as disponibles para este libro.")
        
        sentiment_counts = Counter(sentiments)
        
        # Crear un DataFrame para la distribuci√≥n de sentimientos
        sentiment_df = pd.DataFrame(sentiment_counts.items(), columns=['Sentimiento', 'Cantidad'])
        
        # Ordenar los sentimientos en el orden deseado
        ordered_sentiments = ['Muy positivo', 'Positivo', 'Neutral', 'Negativo', 'Muy negativo']
        sentiment_df['Sentimiento'] = pd.Categorical(sentiment_df['Sentimiento'], categories=ordered_sentiments, ordered=True)
        
        # Ordenar el DataFrame por la columna 'Sentimiento' de acuerdo al orden
        sentiment_df = sentiment_df.sort_values('Sentimiento')
    
        # Crear un gr√°fico de barras con Plotly
        fig = px.bar(sentiment_df, 
                     x='Sentimiento', 
                     y='Cantidad', 
                     title='Tipos de Opiniones en las Rese√±as',
                     labels={'Sentimiento': 'Opiniones', 'Cantidad': 'Cantidad de Rese√±as'},
                     color='Sentimiento', 
                     color_discrete_map={
                         'Muy positivo': 'green', 
                         'Positivo': 'lightgreen', 
                         'Neutral': 'gray', 
                         'Negativo': 'orange', 
                         'Muy negativo': 'red'
                     })
        
        # Mostrar el gr√°fico en Streamlit
        st.plotly_chart(fig)
        
        color_map={
            'Muy positivo': 'green', 
            'Positivo': 'lightgreen', 
            'Neutral': 'gray', 
            'Negativo': 'orange', 
            'Muy negativo': 'red'
        }
        sentiment_general = sentiment_counts.most_common(1)[0][0]
        sentiment_color = color_map[sentiment_general]
    
        st.markdown(
                f"""
                <div style="background-color: {sentiment_color}; color: black; padding: 10px; border-radius: 5px; text-align: center; font-size: 18px;">
                    Opinion general de "{book_title}": <b>{sentiment_general}</b>
                </div>
                """, 
                unsafe_allow_html=True
                )    
    else:
        st.rerun()
        
# Funci√≥n para analizar el sentimiento de las rese√±as
def analyze_sentiment(reviews):
    analyzer = SentimentIntensityAnalyzer()
    sentiments = []
    for review in reviews:
        score = analyzer.polarity_scores(review['content'])
        if score['compound'] >= 0.7:
            sentiments.append('Muy positivo')
        elif 0.05 <= score['compound'] < 0.7:
            sentiments.append('Positivo')
        elif -0.05 < score['compound'] < 0.05:
            sentiments.append('Neutral')
        elif -0.7 <= score['compound'] <= -0.05:
            sentiments.append('Negativo')
        else:
            sentiments.append('Muy negativo')
    return sentiments

def get_csv_files():
    return [f for f in os.listdir() if f.endswith('.csv')]

# Main Streamlit app
def main():
    st.title('Estad√≠sticas de Goodreads')

    # Lista de archivos CSV en el directorio
    csv_files = get_csv_files()

    # Sidebar para scraping de nuevos datos
    st.sidebar.header('Scraping de Libros')
    country = st.sidebar.selectbox('Selecciona pa√≠s', list(countries.keys()))

    # Mapeo de duraci√≥n
    duration_labels = {'y': '√öltimos 12 meses', 'm': 'Este mes', 'w': 'Esta semana'}
    duration_display = list(duration_labels.values())
    selected_duration_label = st.sidebar.selectbox('Selecciona duraci√≥n', duration_display)
    selected_duration = [key for key, value in duration_labels.items() if value == selected_duration_label][0]

    # Al hacer clic en "Scrapear y Guardar CSV"
    if st.sidebar.button('Scrapear y Guardar CSV'):
        try:
            with st.sidebar:
                with st.spinner('Scrapeando datos, suele tardar alrededor de 2 minutos...'):
                    # Perform the scraping and get the filename
                    new_file_name = scrape_and_save(countries[country], selected_duration)
    
                    if new_file_name:
                        # Update the list of CSV files and check if the file exists
                        csv_files = get_csv_files()
                        if new_file_name in csv_files:
                            selected_file = new_file_name
                        else:
                            selected_file = None
    
                        st.success(f'¬°Scraping completado! Archivo guardado como: {new_file_name}')
                    else:
                        st.error('El scraping no gener√≥ ning√∫n archivo v√°lido.')
    
        except Exception as e:
            st.error(f"Error: {str(e)}")


    # Mostrar opciones solo si no hay archivo cargado
    if 'uploaded_file' in st.session_state and st.session_state.uploaded_file is not None:
        uploaded_file = st.session_state.uploaded_file
        st.sidebar.empty()  # Eliminar los componentes del sidebar para mostrar solo el archivo cargado
        
        # Leer el archivo CSV cargado
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df  # Guardar el DataFrame en session_state

        # Mostrar los insights
        show_main_insights(df)
        analyze_book_reviews(df)
    else:
        # Si no hay archivo cargado, mostrar las opciones del sidebar
        st.sidebar.markdown(
        "<div style='color:grey;text-align:center'><br><br> ‚Äî &nbsp;&nbsp;&nbsp;o tambi√©n puedes &nbsp;&nbsp;&nbsp; ‚Äî \n \n<br><br></span>",
        unsafe_allow_html=True
        )
        selected_file = st.sidebar.selectbox('Cargar un archivo CSV', [''] + csv_files)
        uploaded_file = st.sidebar.file_uploader("Subir tu propio archivo CSV", type=["csv"])

        # Verificar si se ha cargado un archivo
        if uploaded_file is not None:
           st.sidebar.empty()  # Eliminar los componentes del sidebar para mostrar solo el archivo cargado
           # Leer el archivo CSV cargado
           df = pd.read_csv(uploaded_file)
           st.session_state.df = df  # Guardar el DataFrame en session_state
           # Mostrar los insights
           show_main_insights(df)
           analyze_book_reviews(df)

        elif selected_file:
            # Si se ha seleccionado un archivo desde la lista
            df = pd.read_csv(selected_file)
            st.session_state.df = df  # Guardar el archivo en session_state
            show_main_insights(df)
            analyze_book_reviews(df)

        elif 'df' in st.session_state:
            # Si hay un archivo almacenado en session_state (como resultado de scraping o selecci√≥n previa)
            df = st.session_state.df
            show_main_insights(df)
            analyze_book_reviews(df)

        else:
            # Si no se ha seleccionado ni subido ning√∫n archivo
            st.write("Por favor, scrapea los datos o selecciona un archivo CSV desde tu ordenador.")


if __name__ == '__main__':
    main()